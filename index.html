<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>顔認証システム</title>
<style>
body { font-family: Arial, sans-serif; text-align: center; }
#videoContainer { position: relative; width: 640px; height: 480px; margin: 0 auto; }
#video, #overlay { position: absolute; top: 0; left: 0; transform: scaleX(-1); }
button { margin: 10px; padding: 10px 20px; font-size: 16px; }
#status { font-weight: bold; margin: 20px 0; }
#instruction { font-style: italic; }
.loading { display: none; }
#confirmationContainer { display: none; margin-top: 20px; }
#capturedImage { max-width: 100%; margin-bottom: 10px; }
#guideOverlay {
    position: absolute;
    top: 0;
    left: 0;
    width: 640px;
    height: 480px;
    border: 2px solid #fff;
    box-sizing: border-box;
}
#faceGuide {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    width: 200px;
    height: 250px;
    border: 2px solid #00ff00;
    border-radius: 50% 50% 50% 50% / 60% 60% 40% 40%;
}
</style>
</head>
<body>
<h1>顔認証システム</h1>
<p>顔認証を行いますか？</p>
<button id="startButton">はい、始めます</button>
<button id="noButton">いいえ、やめます</button>
<div id="loadingIndicator" class="loading">
<p>処理中...</p>
<progress></progress>
</div>
<p id="status"></p>
<div id="videoContainer" style="display: none;">
<video id="video" width="640" height="480"></video>
<canvas id="overlay" width="640" height="480"></canvas>
<div id="guideOverlay">
    <div id="faceGuide"></div>
</div>
</div>
<canvas id="canvas" width="640" height="480" style="display:none;"></canvas>
<p id="instruction"></p>
<p id="result"></p>
<div id="confirmationContainer">
<img id="capturedImage" alt="検出された顔">
<p>この画像で認証を行いますか？</p>
<button id="confirmYesButton">はい</button>
<button id="confirmNoButton">いいえ、再度撮影</button>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script>
window.onload = async function() {
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const overlay = document.getElementById('overlay');
    const startButton = document.getElementById('startButton');
    const noButton = document.getElementById('noButton');
    const status = document.getElementById('status');
    const instruction = document.getElementById('instruction');
    const result = document.getElementById('result');
    const videoContainer = document.getElementById('videoContainer');
    const loadingIndicator = document.getElementById('loadingIndicator');
    const confirmationContainer = document.getElementById('confirmationContainer');
    const capturedImage = document.getElementById('capturedImage');
    const confirmYesButton = document.getElementById('confirmYesButton');
    const confirmNoButton = document.getElementById('confirmNoButton');
    let model;
    let stream;

    // 顔検出の閾値を設定
    const FACE_CONFIDENCE_THRESHOLD = 0.95;
    const FACE_SIZE_THRESHOLD = 0.5;

    startButton.addEventListener('click', startAuthentication);
    noButton.addEventListener('click', () => {
        status.textContent = 'またのお越しをお待ちしております！';
        startButton.style.display = 'none';
        noButton.style.display = 'none';
    });

    confirmYesButton.addEventListener('click', () => {
        confirmationContainer.style.display = 'none';
        authenticateFace(capturedImage.src);
    });

    confirmNoButton.addEventListener('click', () => {
        confirmationContainer.style.display = 'none';
        videoContainer.style.display = 'block';
        detectFace();
    });

    async function startAuthentication() {
        startButton.disabled = true;
        noButton.disabled = true;
        loadingIndicator.style.display = 'block';
        status.textContent = "システムを準備中...";
        try {
            await initializeCamera();
            await loadFaceDetectionModel();
            detectFace();
        } catch (error) {
            console.error("エラーが発生しました:", error);
            status.textContent = 'エラーが発生しました。ページを再読み込みしてください。';
        } finally {
            loadingIndicator.style.display = 'none';
        }
    }

    async function initializeCamera() {
        status.textContent = "カメラの起動中...";
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        video.srcObject = stream;
        videoContainer.style.display = 'block';
        await video.play();
        status.textContent = "カメラが起動しました。";
    }

    async function loadFaceDetectionModel() {
        status.textContent = "顔認識システムの読み込み中...";
        model = await blazeface.load();
        status.textContent = "顔認識システムの準備完了。";
    }

    async function detectFace() {
        status.textContent = "顔を探しています...";
        instruction.textContent = "顔をガイド枠に合わせてください。";

        async function detect() {
            const predictions = await model.estimateFaces(video, false);
            const ctx = overlay.getContext('2d');
            ctx.clearRect(0, 0, overlay.width, overlay.height);
            ctx.save();
            ctx.scale(-1, 1);
            ctx.translate(-overlay.width, 0);

            if (predictions.length > 0) {
                const face = predictions[0];
                const x = face.topLeft[0];
                const y = face.topLeft[1];
                const width = face.bottomRight[0] - x;
                const height = face.bottomRight[1] - y;

                // 顔の位置と大きさをチェック
                const isCentered = x > 160 && x + width < 480 && y > 120 && y + height < 360;
                const isCorrectSize = width > overlay.width * FACE_SIZE_THRESHOLD && height > overlay.height * FACE_SIZE_THRESHOLD;

                if (isCentered && isCorrectSize && face.probability[0] > FACE_CONFIDENCE_THRESHOLD) {
                    ctx.strokeStyle = "green";
                    ctx.lineWidth = 3;
                    ctx.strokeRect(x, y, width, height);
                    instruction.textContent = "そのまま動かないでください";
                                        setTimeout(() => captureAndConfirm(), 2000);
                    ctx.restore();
                    return;
                } else {
                    ctx.strokeStyle = "red";
                    ctx.lineWidth = 3;
                    ctx.strokeRect(x, y, width, height);
                    if (!isCentered) {
                        instruction.textContent = "顔をガイド枠の中心に合わせてください";
                    } else if (!isCorrectSize) {
                        instruction.textContent = "カメラに近づくか遠ざかってください";
                    } else {
                        instruction.textContent = "顔をはっきりと映してください";
                    }
                }
            } else {
                instruction.textContent = "顔が見つかりません。カメラに向かって正面を向いてください。";
            }

            ctx.restore();
            requestAnimationFrame(detect);
        }

        detect();
    }

    function captureAndConfirm() {
        const tempCanvas = document.createElement('canvas');
        const tempCtx = tempCanvas.getContext('2d');
        tempCanvas.width = video.videoWidth;
        tempCanvas.height = video.videoHeight;
        tempCtx.scale(-1, 1);
        tempCtx.translate(-tempCanvas.width, 0);
        tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

        const imageDataUrl = tempCanvas.toDataURL('image/jpeg', 1.0);  // 最高品質のJPEG
        capturedImage.src = imageDataUrl;
        videoContainer.style.display = 'none';
        confirmationContainer.style.display = 'block';
        status.textContent = "顔を検出しました。確認してください。";
    }

    async function authenticateFace(imageDataUrl) {
        status.textContent = "顔を認証中...";
        instruction.textContent = "";
        loadingIndicator.style.display = 'block';

        try {
            const response = await fetch('https://zwf5nd9yr4.execute-api.ap-southeast-2.amazonaws.com/ABC/authenticate', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: imageDataUrl }),
            });

            console.log('Response status:', response.status);
            const responseText = await response.text();
            console.log('Response text:', responseText);

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = JSON.parse(responseText);
            const bodyData = JSON.parse(data.body);

            console.log('Parsed body data:', bodyData);  // デバッグ用

            if (bodyData.authenticated) {
                result.textContent = `認証成功！ユーザーID: ${bodyData.userId}, 名前: ${bodyData.name}`;
            } else {
                result.textContent = "認証できませんでした。顔登録してください。";
            }
        } catch (error) {
            console.error('認証エラー:', error);
            result.textContent = `認証中にエラーが発生しました: ${error.message}`;
        } finally {
            status.textContent = "認証プロセスが完了しました。";
            loadingIndicator.style.display = 'none';
            video.pause();
            stream.getTracks().forEach(track => track.stop());
        }
    }
};
</script>
</body>
</html>
